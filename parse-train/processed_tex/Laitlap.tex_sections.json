{
    "sections": {
        "doco:title": "Preconditioned Uzawa-type   method for a state constrained   parabolic optimal control problem with boundary control",
        "doco:abstract": "Iterative solution method for mesh approximation of  an optimal control problem of a system governed by  a linear parabolic equation is constructed and investigated.  Control functions of the problem are in the right-hand side of the equation and in Neumann  boundary condition, observation is in a part of the domain. Constraints on the control functions,  state function and its time derivative are imposed. A mesh  saddle point problem is constructed and preconditioned Uzawa-type method is applied to its solution. The main advantage of the iterative method is its effective implementation:  every iteration step consists of   the pointwise  projections onto the segments and solving the linear mesh parabolic equations.",
        "doco:list_of_authors": "A.~Lapin and E.~Laitinen",
        "doco:email": "",
        "doco:subtitle": "",
        "doco:keywords": "parabolic optimal control problem, mesh approximation, state constraints, \nsaddle point problem, iterative method",
        "doco:introduction": "\nState constrained parabolic optimal control problems arise when  solving  real world applications (see   \\cite{CC}, \\cite{cristall}   and bibliography therein). While state constrained elliptic optimal control problems  are thoroughly investigated, only a few contributions are known on numerical analysis of  state constrained parabolic optimal control problems \\cite{Neitzel} -- \\cite{lala1}. In \\cite{Neitzel}, \\cite{Deck} the problems with point-wise constraints for the state function are investigated. In particular,  Lavrentiev-type regularization is  applied to  the problems  with distributed and   boundary control in \\cite{Neitzel}, and  error bounds for control and state mesh functions are obtained in \\cite{Deck} when  approximating  the state equation by linear finite elements in space and a discontinuous Galerkin scheme in time.\nIn \\cite{lala},\\cite{lala1}    new iterative solution methods are proposed for finite-dimensional approximations of the problems with point-wise bounds on  time derivative of the state. In our knowledge the convergence of  mesh approximations of the parabolic optimal problems with constraints for   time derivative of the state is not investigated.\n\nA common way to solve optimal control problems consists of  using  Lagrange functions and constructing the iterative solution methods for the corresponding saddle point problems.  Unconstrained saddle point problems are thoroughly  investigated (see survey paper  \\cite{Saddle}\ncontaining exhaustive list of references on this subject and recent articles \\cite{Shaible}, \\cite{Pan}).  The development of the efficient numerical methods to\nsolve  large scale constrained saddle-point problems is too far from complete. In this way,    Uzawa, Arrow-Hurwitz and\noperator-splitting iterative  methods for the constrained saddle point problems arising from  augmented Lagrangian approach are investigated in  monographs  \\cite{fortin},  \\cite{letal}. Solution methods for different classes of the constrained saddle point problems can be found  in \\cite{Pop} -- \\cite{Marat}.\n\n\nIn this paper we consider a parabolic optimal control problem with distributed and boundary control  and with observation  in a part of the domain. Constraints on the  control, state and on time derivative of state are imposed.  We approximate this problem by finite element in space and weighted finite difference in time scheme, prove the existence of a solution and construct iterative solution method.\n\n We construct preconditioned  Uzawa-type iterative solution method   with block diagonal  preconditioner for  the corresponding saddle point problem.\nThe  preconditioner is   energy equivalent to   the \"main\" matrix of the problem with the constants of the equivalence which don't depend on mesh parameters. The crucial point in constructing the  effectively implemented Uzawa type methods  is an equivalent transformation of the original saddle point problem following \\cite{La1}.\n\n%%xxxxxxxxxxxxxxx%%%Well-known approach to  constructing the  iterative methods for variational inequalities with constraints on the gradient of solution is based on the introduction of a new variable  equal to  the gradient of solution and constructing Lagrangian functions. The most popular  iterative methods for this class of problems use  augmented Lagrangian technique \\cite{LGT} - \\cite{letal}. Some other iterative  methods are proposed and   investigated in   \\cite{La} - \\cite{la-3new}. These  methods can be embedded to the class of preconditioned one-step methods for the inclusions with monotone operators. They  are effectively implementable  when solving the   variational inequalities with potential  operators: on every iterative step one has to solve only a system of linear equations and a set of two-dimensional minimization problems. On the other hand,  when solving a variational inequality with nonlinear diffusion-convection operator   it is necessary to solve on every step a system of nonlinear equations instead of linear ones, and this is the most time consuming part of the algorithms. In \\cite{la-3new} a new Uzawa-type method was proposed and investigated for a finite dimensional constrained saddle point problem. This method being applied to finite element approximation of variational inequality with nonlinear diffusion-convection  operator keeped the same efficiency of the implementation as in the case of potential operator.",
        "doco:conclusion": "",
        "doco:acknowledgements": "",
        "doco:chapter": [
            "\\label{formulations}\nLet $\\Omega \\subset \\mathbb{R}^2$ be a bounded domain with the\nboundary $\\partial \\Omega=\\Gamma_D\\cup \\Gamma_N,$${\\rm meas \\;}\n\\Gamma_D > 0$ and let   $\\Omega_1\\subseteqq \\Omega$ be its subdomain. Let further   $Q_T=\\Omega\\times (0,T]$, $Q_1=\\Omega_1\\times (0,T],$$\\Sigma_D=\\Gamma_D\\times (0,T]$  and $\\Sigma_N=\\Gamma_N\\times (0,T]$. Denote by  $V=\\{ u \\in H^1(\\Omega): u(x)=0 \\text{  on }\\Gamma_D\\}$  Sobolev space   with inner product $\\displaystyle (u,v)=\\int\\limits_{\\Omega} \\nabla u\\cdot \\nabla v\\, {\\rm d} x$ and norm  $\\|u\\|=(u,u)^{1/2}$.\n\n\nWe consider a parabolic initial-boundary value problem\n%Define a state problem with two control functions $u$  and $q$:\\begin{equation}\\label{state}\n\\begin{array}{c}\n\\displaystyle\\frac{\\partial y}{\\partial t}-\\Delta y=u\\; \\mbox{in}\\; Q_T,\\\\\n\\displaystyle y=0 \\;  \\mbox{on}\\; \\Sigma_D,\\;\\frac{\\partial y}{\\partial n}=q \\;  \\mbox{on}\\; \\Sigma_N,\\\\\n y=0\\; \\mbox{for}\\; t=0,\\, x\\in \\Omega,\n\\end{array}\n\\end{equation}\nwhich will be a state equation. The functions $u=u(x,t)$  and $q=q(x,t)$ are variable control functions, and the solution $y(x,t)$ of \\eqref{state} is a state function.\n\\begin{proposition}(\\cite{LM}, p. 34)\nLet $\\partial \\Omega\\in C^2$, $u \\in L_2(Q_T)$ and $q\\in W=L_2(0,T;H^{1/2}(\\Gamma_N))\\cap H^{1/4}(0,T; L_2(\\Gamma_N))$. Then  there exists a unique solution $y$ of problem \\eqref{state}, such that\n $\\displaystyle y\\in L_{\\infty}(0,T; V)\\cap H^1(0,T; L_2(\\Omega))$ and the following stability inequality takes place:\n\\begin{equation}\\label{stabil}\n\\sup\\limits_{0\\leqslant t \\leqslant T}\\|y(t)\\|_{V}+\\|\\displaystyle \\frac{\\partial y(t)}{\\partial t}\\|_{L_2(Q_T)}\\leqslant C_a\\left(\\|u(t)\\|_{L_2(Q_T)}+\\|q(t)\\|_{W}\\right),\\;C_a=const.\n\\end{equation}\n\\end{proposition}%Further we suppose that the solution of problem \\eqref{state} satisfies the aforementioned regularity properties and inequality \\eqref{stabil}.\nThe mentioned regularity properties of state function  $y$ allow to define, in particular,  the point-wise constraints for its time derivative.  Define the following sets of constraints:\n\\begin{equation*}\\label{Lap-constraint}\n\\begin{array}{c}\n\\displaystyle U_{ad}=\\{u\\in L_2(Q_T):\\, |u(x,t)|\\leqslant u_{\\max}\\;\\mbox{a.e.}\\; (x,t)\\in Q_T\\},\\\\\n\\displaystyle Q_{ad}=\\{q\\in W:\\;  |q|\\leqslant \\bar q\\;\\mbox{a.e.}\\;  \\Sigma_N\\},\\\\\n\\displaystyle Y_{ad}=\\{y\\in L_2(0,T; H^1_0(\\Omega)):\\, \\displaystyle \\frac{\\partial y}{\\partial t}\\in L_2(Q_T),\\;\\;y_{\\min}\\leqslant y(x,t)\\leqslant y_{\\max}\\\\\n\\displaystyle \\mbox{and}\\; dy_{\\min}\\leqslant \\displaystyle\\frac{\\partial y}{\\partial t}\\leqslant dy_{\\max}\\;\\mbox{a.e.}\\; Q_T\\}.\n\\end{array}\n\\end{equation*}\nAbove constants  $\\bar u>0$, $\\bar q>0$ and $ -\\infty\\leqslant y_{\\min}, dy_{\\min} < 0< y_{\\max}, dy_{\\max}\\leqslant \\infty$.\n\nLet an   objective function be defined by the equality\n\\begin{equation}\\label{object}\n\\displaystyle J(y,u,q)=\\frac 1 2 \\int\\limits_{Q_1}(y(x,t)-y_d(x,t))^2 dx dt+\\frac 12  \\int\\limits_{Q_T}u^2 dxdt+\\frac 12  \\int\\limits_{\\Sigma_N} q^2 d\\Gamma dt\n\\end{equation}\nwith a given observation function $y_d(x,t)\\in L_2(Q_1)$.\n\nWe will solve the following optimal control problem:\n\\begin{equation}\\label{optim}\n\\begin{array}{c}\n\\min\\limits_{(y,u,q)\\in K} J(y,u,q),\\\\\nK=\\{(y,u,q)\\in Y_{ad}\\times U_{ad}\\times Q_{ad}:\\; \\mbox{equation \\eqref{state} holds}\\}.\n\\end{array}\n\\end{equation}\\begin{lemma}\\label{exist}\nProblem \\eqref{optim} has a unique solution $(y,u,q)$.\n\\end{lemma}\\begin{proof}\nThe sets of constraints  $U_{ad}$, $Q_{ad}$  and $Y_{ad}$ are convex,  closed and contain zero elements, moreover   $U_{ad}$ and $Q_{ad}$ are bounded. These properties together with linearity of state equation  and stability inequality \\eqref{stabil} ensure that the set $K$ is convex, closed,  bounded and nonempty. Functional  $J=J(y,u,q)$ is continuous.  The established  properties of\n$J$ and $K$ ensure the existence of a solution to  problem \\eqref{optim}.\nIts uniqueness follows from the strict\nconvexity of the  functional $J$  on the set $K$. To prove this\nproperty of  $J$ we observe that it  is   convex in $y$ and  strictly convex in  $u$ and $q$, and  the\nequalities  $u_1=u_2$ and $q_1=q_2$  imply $y_1=y_2$ for the solutions of problem \\eqref{state}.\n\\end{proof}\\medskip\nWe construct an approximation of problem\n\\eqref{optim} supposing for the simplicity  that the  domains $\\Omega$ and $\\Omega_1$ have polygonal\nboundaries and  that the function $y_{d}$  is continuous.\n\nLet a  family $T_h$ of nonoverlapping closed triangles $e$(finite elements)\n with maximal diameter   $h$   compose  a conforming and regular triangulation $\\overline \\Omega = \\bigcup \\limits_{e\\in\nT_h} e$  of $\\overline \\Omega$(\\cite{Ciarlet}, p.124). We suppose that  $T_h$ generates the triangulations $T^1_h$ on\n$\\overline \\Omega_1$ and $\\partial T_h$ on $ \\overline\\Gamma_N$, i.e.\n $\\overline\\Omega_1$ consists of integer number of $e\\in T_h$ and $\\overline\\Gamma_N$ consists of integer number of sides\n$\\partial e$ of elements $e\\in T_h$.  Define the finite element space $V_h\\subset V$ of the continuous and piecewise linear\nfunctions (linear on each $e$) which vanish on the boundary $ \\Gamma_D$ and the finite element space  $U_h\\in L_2(\\Gamma_N)$ of\nthe piecewise linear functions on $\\Gamma_N$(linear on each $\\partial e\\in \\Gamma_N$), which are  the traces on $\\Gamma_N$ of the functions from\n $V_h$.\n\nTo approximate the integrals of a continuous function $g(x)$ over a finite element $e\\in T_h$ or its side $\\partial e$ we use the quadrature formulas\n$$\n\\int\\limits_{e} g(x) dx\\approx S_{e}(g)=\\frac 13\\, {\\rm meas}\\, (e)\n\\sum_{\\alpha=1}^{3} g(x_{\\alpha}),\\; x_{\\alpha} \\, \\mbox{ are the\nvertices of } e,\n$$$$\n\\int\\limits_{\\partial e} g(x) d\\Gamma \\approx S_{\\partial\ne}(g)=\\frac 12\\, {\\rm meas}\\,  (\\partial e) \\sum_{\\alpha=1}^{2}\ng(x_{\\alpha}),\\; x_{\\alpha} \\, \\mbox{ are the vertices of }\n\\partial e.\n$$\nThe corresponding composite quadrature formulas are\n$$\nS_{\\Omega}(g)=\\sum\\limits_{e\\in T_h} S_e(g), \\;\\;\nS_{\\Omega_1}(g)=\\sum\\limits_{e\\in T^1_h} S_e(g), \\;\\;\nS_{\\Gamma}(g)=\\sum\\limits_{ \\partial e\\in \\partial T_h} S_{\\partial\ne} (g).\n$$\nLet further $\\omega_t=\\{t_j=j\\tau,\\, j=0,1,\\ldots N_t;\\, N_t\\tau =T\\}$ be a  uniform mesh on the segment $[0,T]$. We  denote by $y_h$ with subscript $h$ a mesh function from the space $V_h$ or  $U_h$  and  by   $y_h^j$ a time depending mesh function    at a time level  $t_j\\in \\omega_t$.\nLet also  $y^j_{dh}$ be the continuous and piecewise linear in space variables function which  coincides with $y_d(x,t_j)$ at the nodes of the triangulation $T^1_h$.\n\n\n\\medskip%To construct a mesh optimal control problem we approximate the state equation, constraints sets and objective function ....\nApproximation of state problem \\eqref{state}  is the following  weighted finite-difference in time and finite element in space problem:\n\\begin{multline}\\label{state-appr1}\n\\displaystyle S_{\\Omega}\\left(\\frac{y_h^j-y_h^{j-1}}{\\tau} z_h\\right)+\n\\displaystyle S_{\\Omega}\\left(\\nabla (\\sigma y_h^j+(1-\\sigma)y_h^{j-1}) \\cdot\\nabla  z_h\\right)= \\\\ =S_{\\Omega}(u_h^j\\, z_h) +S_{\\Gamma}(q^j_h \\,z_h)\\;\\forall\nz_h\\in V_h,\\; j=1,2,\\ldots, N_t,\n \\end{multline}\n with initial value $y_h^0=0$ and a weight $\\sigma\\in [0,1]$. This scheme includes: forward Euler ($\\sigma=0$), backward Euler ($\\sigma=1$) and Crank-Nicolson ($\\sigma=1/2$) schemes.\n\nDefine the approximations of the  objective function and the sets of constraints by the following equalities:\n\\begin{equation}\\label{mesh-function}\n\\displaystyle J_{h}(y_h, u_h, q_h)=\\frac \\tau 2\\, \\sum\\limits_{j=1}^{N_t} \\big(S_{\\Omega_1}((y_h^j-y_{d\\,h}^j)^2)+S_{\\Omega}(u_h^j)^2+S_{\\Gamma}(q_h^j)^2\\big),\n\\end{equation}\\begin{equation}\\label{mesh-constraints}\n\\begin{array}{c}\n\\displaystyle U^h_{ad}=\\{|u_h^j| \\leqslant \\bar u\\; \\forall x\\in \\Omega, \\; j=1,2,\\ldots, N_t \\},\\\\\n\\displaystyle Q^h_{ad}=\\{|q_h^j|\\leqslant \\bar q\\; \\forall x\\in \\Omega, \\; j=1,2,\\ldots, N_t\\},\\\\\n\\displaystyle Y^h_{ad}=Y^h_{0}\\bigcap Y^h_{1},\\; Y^h_{0}=\\{y_h^j: \\displaystyle y_{\\min}\\leqslant y_h^j\\leqslant y_{\\max}, \\; \\forall x\\in \\Omega, \\; j=1,2,\\ldots, N_t\\},\\\\\n\\displaystyle  Y^h_{1}=\\{y: \\displaystyle\\tau dy_{\\min}\\leqslant y_h^j-y_h^{j-1}\\leqslant \\tau dy_{\\max}\\;  \\forall x \\in\\ \\Omega, \\; j=1,2,\\ldots, N_t, \\; (y_h^0=0)\\}.\n\\end{array}\n\\end{equation}\nApproximation procedures result to the following mesh optimal control problem:\n\\begin{equation}\\label{oc-appr}\n\\begin{array}{c}\n\\displaystyle \\mbox{find}\\; \\min\\limits_{(y_h,u_h, q_h)\\in K_{h}} J_{h}(y_h,u_h, q_h),\\\\\n\\displaystyle  K_{h}=\\{(y_h,u_h, q_h):\\,y_h\\in Y^h_{ad},\nu_h\\in U^h_{ad}, \\, q_h\\in Q^h_{ad}, \\,\\mbox{  equation }\\,\n\\eqref{state-appr1}\\, \\mbox{ holds}\\}\n\\end{array}\n\\end{equation}\\begin{lemma}\nMesh optimal control problem \\eqref{oc-appr} has a   unique\nsolution $(y_h,u_h, q_h)$.\n\\end{lemma}\\begin{proof}\nSimilar to lemma \\ref{exist} the result follows from the facts that the set $K_h$ is\nnonempty, closed, convex and bounded, while the function $J_h$ is\ncontinuous and strictly convex on $K_h$.\n\\end{proof}\nIt is well-known that   problem \\eqref{state-appr1} is unconditionally stable for $\\sigma \\geqslant 1/2$. In the case $0\\leqslant \\sigma <1/2$ it is stable under the additional condition for time-step $ \\tau<\\tau_0(h)\\simeq h^{2}$. More precisely, the following statement takes place (this is a slightly modified result of \\cite{QV}, p.391):\n\\begin{proposition}\nLet in the case $ 0\\leqslant \\sigma<1/2$\n$$\n\\tau\\leqslant 2(\\nu_{\\max}(1-2\\sigma))^{-1},\n$$\nwhere   $\\nu_{\\max}$   is the  maximal  eigenvalue of  the following eigenvalue problem:\n$$\n(y_h, \\nu):\\;  S_{\\Omega}\\left(\\nabla y_h \\cdot\\nabla  z_h\\right)=\\nu S_{\\Omega}(y_h\\, z_h) \\;\\forall z_h\\in V_h.\n$$\nThen for a solution to problem \\eqref{state-appr1} the following stability inequality holds:\n\\begin{equation}\\label{stability}\n \\sum\\limits_{j=1}^{N_t}  S_{\\Omega} \\left(|y_h^j|^2\\right)\\leqslant  C_T \\, \\left(\\sum\\limits_{j=1}^{N_t} S_{\\Omega}\\left(|u_h^j|^2\\right)+ \\sum\\limits_{j=1}^{N_t} S_{\\Gamma}\\left(|q_h^j|^2\\right)\\right),\\; C_T=const.\n\\end{equation}\n\\end{proposition}",
            "\nDenote by $y\\in {\\mathbb R}^{N_y}$ the vector of nodal values of a function $y_h\\in V_h$($N_y={\\rm dim}.\nV_h$) Then   we get the \"onto\" correspondence $y\\Leftrightarrow y_h$. Similarly a vector $q\\in {\\mathbb R}^{N_q}$ corresponds to\n $q_h\\in Q_h$.\\footnote{ Since hereafter we consider only finite dimensional problems, we use the same notations\nfor the vectors as previously for the functions.}\nBy $(.,.)_y$($(.,.)_q$)  and   $\\|.\\|_y$($\\|.\\|_q$) we denote the inner product and euclidian norm in ${\\mathbb R}^{N_y}$(${\\mathbb R}^{N_q}$) and  by $(.,.)$ and   $\\|.\\|$ -- the inner product and euclidian norm in $ {\\mathbb R}^{N_t N_y}$ and $ {\\mathbb R}^{N_t N_q}$(concrete case will be obvious from the context).\n\nDefine stiffness matrix $A\\in {\\mathbb R}^{N_y\\times N_y}$,   diagonal  matrices $\\tilde M, \\tilde M_y\\in {\\mathbb R}^{N_y\\times N_y}$\n and $\\tilde M_q\\in {\\mathbb R}^{N_q\\times N_q}$, and   rectangular matrix  $ \\tilde S_q\\in {\\mathbb R}^{N_y\\times N_q}$,\n  by the following equalities:\n\\begin{equation}\\label{define-matrices}\n\\begin{array}{c}\n\\displaystyle (A y,z)_y= S_{\\Omega}\\left(\\nabla y_h\\cdot \\nabla z_h\\right),\\; (\\tilde M y,z)_y=S_{\\Omega}(y_h z_h),\\\\ (\\tilde M_y y,z)_y=S_{\\Omega_1}(y_h z_h), \\;\n(\\tilde M_q q,p)_q=S_{\\Gamma}(q_h p_h),\\; (\\tilde S_q q,z)_y=S_{\\Gamma}(q_h z_h).\n\\end{array}\n\\end{equation}\nAbove    $y\\Leftrightarrow y_h\\in V_h, $$z\\Leftrightarrow z_h\\in V_h $ and $q\\Leftrightarrow q_h\\in Q_h,$$p\\Leftrightarrow p_h\\in\nQ_h.$\nWith these notations mesh state equation \\eqref{state-appr1} and objective function \\eqref{mesh-function} can be written for  the vectors of nodal values of mesh functions:\n\\begin{equation}\\label{mesh_state}\n\\displaystyle  \\tilde M \\frac{y^j-y^{j-1}}{\\tau}+A(\\sigma  y^{j}+(1-\\sigma)y^{j-1})=\\tilde M u_j+\\tilde S_q q^j, \\; j=1,2,\\ldots,N_t, y^0=0,\n\\end{equation}\\begin{equation}\\label{mesh_function1}\n\\displaystyle I(y, u, q)=\\frac \\tau 2\\, \\sum\\limits_{j=1}^{N_t} \\big( (\\tilde M_y (y^j-y_{d}^j), y^j-y_{d}^j)_y+(\\tilde Mu^j, u^j)_y+(M_q q^j, q^j)_q\\big).\n\\end{equation}\nFurther we use also  the block diagonal matrices with constant blocks, namely, $\\displaystyle M={\\rm diag} (\\tilde M,\\tilde M,\\ldots, \\tilde M)\\in  {\\mathbb R}^{N_t N_y\\times N_t N_y}$ and similarly defined  $\\displaystyle M_y\\in  {\\mathbb R}^{N_t N_y\\times N_t N_y}$, $\\displaystyle M_q\\in  {\\mathbb R}^{N_t N_q\\times N_t N_q}$ and  $\\displaystyle S_q\\in  {\\mathbb R}^{N_t N_y\\times N_t N_q}$. Define also matrix $\\displaystyle L\\in  {\\mathbb R}^{N_t N_y\\times N_t N_y}$:\n$$\n(Ly)_j=\\{\\displaystyle  \\tilde M \\frac{y^j-y^{j-1}}{\\tau}+A(\\sigma  y^{j}+(1-\\sigma)y^{j-1}), \\; j=1,2,\\ldots,N_t \\},\n$$\nwith formal component $y^0=0$.\n\nNow we can rewrite mesh state equation \\eqref{mesh_state} and objective function \\eqref{mesh_function1} in the following  short manner (we scale objective function by dividing to $\\tau$):\n$$Ly=Mu+S_q q,$$$$I(y, u, q)=\\frac 12\\, (M_y (y-y_{d}), y-y_{d})+\\frac 12\\,(Mu, u)+\\frac 12\\,(M_q q, q).$$\nNote, that stability inequality \\eqref{stability} implies the estimate\n\\begin{equation}\\label{stability1}\n(M y,  y)\\leqslant C_T \\big((Mu,u)+(M_q q,q)\\big).\n\\end{equation}\nPoint-wise constraints \\eqref{mesh-constraints} can be obviously rewritten for the vectors of nodal values of mesh functions.\nLet further\n$$\\displaystyle R\\in {\\mathbb R}^{N_t N_y\\times N_t N_y},\\;(Ry)^j=\\{y^j-y^{j-1}\\;\\mbox{for}\\; j=2,\\ldots, M;\\; y^1\\;\\mbox{for}\\; j=1\\}.$$\nThen we can replace the constraint  $y\\in Y_{ad}^{1h}$ in the discrete   optimal control problem by the following constraints:\n$$\np\\in P^h_{ad}=\\{\\tau dy_{\\min}\\leqslant p_j\\leqslant \\tau dy_{\\max},\\; j=1,2,\\ldots M\\},\\; Ry-p=0.\n$$\nAt last, denote by  $\\psi$, $\\theta$, $\\varphi_u$ and $\\varphi_q$  the indicator functions of the sets  $Y^h_0$, $P_{ad}^h$, $U_{ad}^h$ and $Q_{ad}^h$, respectively.\n\nAs a result  we obtain the following algebraic form of  mesh optimal control problem \\eqref{oc-appr}:\n\\begin{equation}\\label{optim-alg}\n\\min\\limits_{Ly=Mu+S_q q,\\; p=Ry} \\{I(y,u,q)+\\psi(y)+\\theta(p)+\\varphi_u(u)+\\varphi_q(q)\\}.\n\\end{equation}\nConstruct Lagrange function for  problem \\eqref{optim-alg}:\n$$\n{\\mathcal L}(y,u,q,p,\\lambda,\\mu)=I(y,u,q)+\\psi(y)+\\theta(p)+\\varphi_u(u)+\\varphi_q(q)+(\\lambda, Ly-Mu-S_q q)+(\\mu, Ry-p).\n$$\nA saddle point of this Lagrangian satisfies the following saddle point problem (cf., e.g. \\cite{Ekland}, p.169):\n\\begin{equation}\\label{saddle}\n\\begin{pmatrix}\n M_y  & 0&0 &0&L^T &R^T \\\\\n  0 &M&0&0&-M&0\\\\\n  0 &0&M_q&0&-S_q^T&0\\\\\n 0&0&0&0&0&-E\\\\\n  L& -M&-S_q&0&0&0\\\\\n  R&0&0&-E&0&0\n\\end{pmatrix}\n\\begin{pmatrix}\ny \\\\\nu\\\\\nq\\\\\np\\\\\n \\lambda\\\\\n \\mu\n \\end{pmatrix}+\n\\begin{pmatrix}\n\\partial \\psi(y)\\\\\n  \\partial\\varphi_u(u)\\\\\n  \\partial \\varphi_q(q)\\\\\n  \\partial \\theta(p)\\\\\n    0\\\\0\n\\end{pmatrix} \\ni\n\\begin{pmatrix}\nM_y y_d\\\\\n 0\\\\\n 0\\\\\n 0\\\\\n0\n \\\\\n 0\n\\end{pmatrix},\n\\end{equation}\nwhere $\\partial \\psi, \\partial\\varphi_u$,  $\\partial\\varphi_q$ and $\\partial \\theta$ are the subdifferentials of the corresponding functions and $E$ is identity matrix.\nWith the notations  $z=(y,u,q,p)^T$, $\\eta=(\\lambda, \\mu)^T$, $f=(M_y y_d,0,0,0)^T$, $\\Psi(z)=\\psi(y)+\\theta(p)+\\varphi_u(u)+\\varphi_q(q)$,   and\n$${\\mathcal A}=\\begin{pmatrix}\n  M_y& 0 &0&0\\\\\n 0 &  M &0&0\\\\\n 0&0&M_q&0\\\\\n  0&0&0&0\n\\end{pmatrix},\\;\\;B=\\begin{pmatrix}  L& -M&-S_q&0\\\\  R&0&0&-E\\end{pmatrix}\n$$\nproblem \\eqref{saddle} can be rewritten in a compact form:\n\\begin{equation*}\n\\begin{pmatrix}{\\mathcal A} & B^T  \\\\\n  B & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n z \\\\\n   \\eta\n\\end{pmatrix}+\n\\begin{pmatrix}\n \\partial \\Psi(z)\\\\\n0\n\\end{pmatrix} \\ni\n\\begin{pmatrix}\n  f\\\\\n  0\n\\end{pmatrix}\n\\end{equation*}\nThe degenerate matrix ${\\mathcal A}$ is an obstacle to the application of  Uzawa-type iterative methods for solving this saddle point problem. To overcome this deficiency  we use two last equations of system \\eqref{saddle} to transform  it to the equivalent saddle point problem\n\\begin{equation}\\label{general_problem}\n\\begin{pmatrix}{\\mathcal A}_r & B^T  \\\\\n  B & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n z \\\\\n   \\eta\n\\end{pmatrix}+\n\\begin{pmatrix}\n \\partial \\Psi(z)\\\\\n0\n\\end{pmatrix} \\ni\n\\begin{pmatrix}\n  f\\\\\n  0\n\\end{pmatrix}\n\\end{equation}\nwith\n$${\\mathcal A}_{r}=\\begin{pmatrix}\n  M_y+r_1M& -r_1ML^{-1}M &-r_1ML^{-1}S_q&0\\\\\n 0 &  M &0&0\\\\\n 0&0&M_q&0\\\\\n  -r_2 M R&0&0&r_2M\n\\end{pmatrix},\\; r_1>0, r_2>0,\n$$\ninstead of ${\\mathcal A}$ and with the same matrix $B$ and function $\\Psi$.\n\\begin{lemma}\\label{equiv}\nLet $\\displaystyle (r_1, r_2)\\in \\omega=\\{0<r_1<\\frac 2{C_T},\\; 0<r_2<r_1-\\frac{r_1^2C_T}2\\}$. Then matrix  ${\\mathcal A}_{r}$  is positive definite  and energy equivalent to block-diagonal matrix $${\\mathcal A}_{00}={\\rm diag}\\begin{pmatrix}  M,& M,& M_q,& M \\end{pmatrix}$$ with constants of the equivalence, which depend only on $r_1, r_2$:\n\\begin{equation}\\label{energy_equiv}\nc_0(r_1, r_2)({\\mathcal A}_{00}z, z)\\leqslant ({\\mathcal A}_{r}z, z)\\leqslant c(r_1, r_2) ({\\mathcal A}_{00}z, z),\\; z=(y,u,q,p)^T.\n\\end{equation}\n\\end{lemma}\\begin{proof} Let  $z=(y,u,q,p)^T$, then\n$$({\\mathcal A}_{r}z,z)=((M_y+r_1M)y,y)-r_1(L^{-1}(Mu+S_qq), M y)+(Mu,u)+$$$$(M_q q,q)+r_2(Mp,p)-r_2(Mp, Ry)\n$$\nDenote by $\\tilde y$ the solution of the equation $L\\tilde y=Mu+S_q q$.\nThen  due to  the stability inequality \\eqref{stability1} $(M\\tilde y, \\tilde y)\\leqslant C_T \\big((Mu,u)+(M_q q,q)\\big).$\nUsing  this estimate  and the inequality $|(Ry,Mp)|\\leqslant 2(My,y)^{1/2} (Mp,p)^{1/2}$ we get\n\\begin{multline*}\n({\\mathcal A}_{r}z,z)\\geqslant r_1(My,y) +(Mu,u)+(M_q q,q)+r_2(M p,p)-\\\\- r_1C^{1/2}_T(Mu,u)^{1/2}(My,y)^{1/2}- r_1C^{1/2}_T(M_q q,q)^{1/2}(My,y)^{1/2}-2 r_2 (My,y)^{1/2}\n(M p,p)^{1/2}.\n\\end{multline*}\nFor $(r_1, r_2)\\in \\omega$ the quadratical form $F(y,u,q,p)=r_1 y^2+u^2+q^2+r_2p^2- r_1C^{1/2}_T uy - r_1C^{1/2}_T q y -2r_2yp$ is positive definite and there exists $c_0>0:\\;  F(y,u,q,p)\\geqslant c_0 (y^2+u^2+q^2+p^2)$. As a consequence\n$$\n({\\mathcal A}_{r}z,z)\\geqslant c_0 ({\\mathcal A}_{00}z,z).\n$$\nSince $(M_y y,y)\\leqslant (My,y)$, we obtain\n\\begin{multline*}\n({\\mathcal A}_{r}z,z)\\leqslant (1+ r_1) (My,y) +(Mu,u)+(M_q q,q)+r_2(M p,p)+\\\\+ r_1C^{1/2}_T(Mu,u)^{1/2}(My,y)^{1/2}+ r_1C^{1/2}_T(M_q q,q)^{1/2}(My,y)^{1/2}+2 r_2 (My,y)^{1/2} (M p,p)^{1/2},\n\\end{multline*}\nwhence\n$$\n({\\mathcal A}_{r}z,z)\\leqslant c_1 ({\\mathcal A}_{00}z,z)\n$$\nwith a constant $c_1$ depending on $r_1$ and $r_2$.\n\\end{proof}\\begin{theorem}\\label{exist-saddle}\nProblem  \\eqref{saddle} has a solution  $(y,u,q, p,\\lambda,\\mu)$ with unique  $y,u,q,p$, which coincide with the solution of problem  \\eqref{optim-alg}.\n\\end{theorem}\\begin{proof}\nMatrix ${\\mathcal A}_{r}$ is positive definite, matrix  $B$ has a full column rank and function $\\Psi$ is convex, proper and lower semicontinuous.\nMoreover, zero vector satisfies the equation $Bz=0$ and belongs to ${\\rm int\\, dom}\\, \\Psi$. All these properties ensure the result of the theorem (cf. \\cite{la-3}).\n\\end{proof}",
            "\nA preconditioned Uzawa-type iterative method for solving saddle point problem \\eqref{general_problem} reads as follows:\n\\begin{equation}\\label{Udzawa1}\n\\begin{array}{c}{\\mathcal A}_rz^{k+1}+\\partial \\Psi(z^{k+1})\\ni B^T \\eta^k+f,\\\\\n\\displaystyle  \\dfrac 1 \\rho D (\\eta^{k+1} - \\eta^k)\n+ Bz^{k+1}= 0,\n\\end{array}\n\\end{equation}\nwhere $D$ is  a symmetric and positive definite matrix (preconditioner), $\\rho>0$ is an iterative parameter.\nIterative method  \\eqref{Udzawa1} converges\nfor any initial guess  $\\eta^0$  if the pair \"preconditioner $D$ - parameter $\\rho$\" satisfies  the following  assumption (\\cite{La1}):\n\\begin{equation}\\label{AB}\n D\\geqslant \\frac{(1+\\varepsilon) \\rho}{2}B{\\mathcal A}_{rs}^{-1}B^T,\\;\\; \\varepsilon>0,\n\\end{equation}\nwhere $ {\\mathcal A}_{rs}=0.5({\\mathcal A}+{\\mathcal A}^T)$ is the symmetric part of ${\\mathcal A}_r$.\n\nBelow we construct an easy invertible block diagonal   preconditioner $D$  which is spectrally equivalent to $B{\\mathcal A}_{rs}^{-1}B^T$ with the constants, which  don't depend on meshsizes $h$ and $\\tau$.\n\n\n\nDue to lemma  \\ref{equiv} the  matrix $B {\\mathcal A}_{rs}^{-1}B^T$  is spectrally equivalent to\n$$\n B {\\mathcal A}_{00}^{-1}B^T=\\begin{pmatrix}\nLM^{-1}L^T+M+S_qM_q^{-1}S_q^T  &LM^{-1}R^T \\\\\n  RM^{-1}L^T&RM^{-1}R^T+M^{-1}\n\\end{pmatrix}.$$\nIn turn, this matrix is spectrally equivalent to a block-diagonal one. More precisely, the following statement takes place:\n\\begin{lemma}\nMatrix\n$\\displaystyle D=\\begin{pmatrix}\nLM^{-1}L^T  &0 \\\\\n  0&M^{-1}\n\\end{pmatrix}$ is spectrally equivalent to  $\\displaystyle B {\\mathcal A}_{00}^{-1}B^T$ with constants, which don't depend on meshsizes $h$ and $\\tau$. In particular,\n\\begin{equation}\\label{spectr-equiv}\n(B {\\mathcal A}_{00}^{-1}B^T \\eta, \\eta)\\leqslant (1+C_T+\\sqrt{C^2_T+4}) (D\\eta, \\eta)\\; \\forall \\eta=(\\lambda, \\mu).\n\\end{equation}\n\\end{lemma}\\begin{proof}\nUsing the inequalities\n$$(M\\lambda, \\lambda)+(M_q^{-1}S_q^T \\lambda, S_q^T \\lambda)\\geqslant 0\\; \\mbox{and}\\;(M^{-1}R^T \\mu, R^T \\mu)\\leqslant 4 (M^{-1}\\mu,\\mu)$$\nwe estimate the quadratical form $(B {\\mathcal A}_{00}^{-1}B^T \\eta, \\eta)$ from below:\n\\begin{multline*}\n(B {\\mathcal A}_{00}^{-1}B^T \\eta, \\eta)=(M^{-1}L^T\\lambda, L^T\\lambda)+(M\\lambda, \\lambda)+(M_q^{-1}S_q^T \\lambda, S_q^T \\lambda)+\\\\\n+(M^{-1}R^T \\mu, R^T \\mu)+(M^{-1}\\mu,\\mu)+2(M^{-1}L^T,R^T \\mu)\\geqslant \\\\ \\geqslant (1-\\frac 1{\\varepsilon})(M^{-1}L^T\\lambda, L^T\\lambda)+(1-\\varepsilon)(M^{-1}R^T \\mu, R^T\\mu)+\\\\+(M^{-1}\\mu,\\mu)\\geqslant (1-\\frac 1{\\varepsilon})(M^{-1}L^T\\lambda, L^T\\lambda)+(1-4|1-\\varepsilon|)(M^{-1}\\mu,\\mu).\n\\end{multline*}\nFor a fixed $\\displaystyle 0<\\varepsilon<\\frac{\\sqrt2 -1}{2}$ we get $(B {\\mathcal A}_{00}^{-1}B^T \\eta, \\eta) \\geqslant c(\\varepsilon)(D\\eta, \\eta),\\; c(\\varepsilon)>0.$\n\nLet us prove  estimate \\eqref{spectr-equiv}. For any $\\varepsilon>0$ we have\n\\begin{multline}\\label{otz1}\n(B {\\mathcal A}_{00}^{-1}B^T \\eta, \\eta)\\leqslant (1+\\frac 1{\\varepsilon})(M^{-1}L^T\\lambda, L^T\\lambda)+(M\\lambda, \\lambda)+\\\\+(M_q^{-1}S_q^T \\lambda, S_q^T \\lambda)+(1+4 \\varepsilon) (M^{-1}\\mu,\\mu).\n\\end{multline}\nDue to Cauchy inequality and stability estimate \\eqref{stability1} the following chain of the inequalities is true:\n\\begin{multline*}\n\\|M^{-1/2} L^T \\lambda\\|=\\sup\\limits_{v}\\, \\frac{(M^{-1/2} L^T \\lambda,v)}{\\|v\\|}=\\sup\\limits_{y}\\, \\frac{( \\lambda, L y)}{\\| M^{1/2} y\\|}\\geqslant\\\\ \\geqslant \\sup\\limits_{u,q}\\, \\frac{( \\lambda, Mu+S_q q)}{\\| M^{1/2} (L^{-1}(Mu+S_q q)\\|}\\geqslant\\frac 1{C^{1/2}_T} \\sup\\limits_{u,q}\\, \\frac{( \\lambda, Mu+S_q q)}{\\|M^{1/2}u\\|+\\|S_q^{1/2} q\\|}.\n\\end{multline*}\nChoosing  subsequently $q=0$ and $u=0$ in this inequality we have\n\\begin{equation}\\label{otz}\n\\begin{array}{c}\n\\displaystyle \\|M^{-1/2} L^T \\lambda\\|\\geqslant\\frac 1{C^{1/2}_T} \\sup\\limits_{u}\\, \\frac{( \\lambda, Mu)}{\\|M^{1/2}u\\|}= \\frac 1{C^{1/2}_T}\\|M^{1/2}\\lambda\\|,\\\\\n\n\\displaystyle  \\|M^{-1/2} L^T \\lambda\\|\\geqslant\\frac 1{C^{1/2}_T} \\sup\\limits_{q}\\, \\frac{( \\lambda, S_q q)}{\\|S_q^{1/2} q\\|}= \\frac 1{C^{1/2}_T}\\|M^{-1/2} S_q^T\\lambda\\|.\n\\end{array}\n\\end{equation}\nEstimates  \\eqref{otz1} and \\eqref{otz} yield\n$$\n(B {\\mathcal A}_{00}^{-1}B^T \\eta, \\eta) \\leqslant (1+\\frac 1{\\varepsilon}+2 C_T)(M^{-1}L^T\\lambda, L^T\\lambda)+(1+4 \\varepsilon) (M^{-1}\\mu,\\mu).\n$$\nFor $\\varepsilon=\\displaystyle \\frac{C_T+\\sqrt{C^2_T+4}}{4}$ we get estimate \\eqref{spectr-equiv}.\n\\end{proof}\nMethod \\eqref{Udzawa1} for problem  \\eqref{saddle}  with  preconditioner $\\displaystyle D=\\begin{pmatrix}\nLM^{-1}L^T  &0 \\\\\n  0&M^{-1}\n\\end{pmatrix}$ reads as follows:\n\\begin{equation}\\label{iter}\n\\begin{cases}\nM u^{k+1}+\\partial\\varphi_u(u^{k+1})\\ni M \\lambda^{k},\\\\\nM_q q^{k+1}+\\partial\\varphi_q(q^{k+1})\\ni S_q^T \\lambda^{k},\\\\\n(M_y+r_1M)y^{k+1}+ \\partial \\psi(y^{k+1})\\ni My_d + r_1ML^{-1}Mu^{k+1}+\\\\+r_1ML^{-1}S_q q^{k+1} -L^T \\lambda^k-R^T\\mu^k,  \\\\\nr_2M p^{k+1}+\\partial \\theta(p^{k+1})\\ni r_2 MRy^{k+1}+\\mu^k,\\\\\n\\end{cases}\n\\end{equation}\\begin{equation}\\label{iter1}\n\\begin{cases}\n\\displaystyle LM^{-1}L^T\\frac{\\lambda^{k+1}-\\lambda^k}{\\rho}=Ly^{k+1}- Mu^{k+1}-S_q q^{k+1},\\\\\n\\displaystyle \\frac{\\mu^{k+1}-\\mu^k}{\\rho}=MRy^{k+1}-Mp^{k+1}.\n\\end{cases}\n\\end{equation}\\begin{theorem}\nMethod \\eqref{iter}, \\eqref{iter1} converges if  $(r_1, r_2)\\in \\omega$ and\n\\begin{equation}\\label{iter-step}\n\\displaystyle 0<\\rho< \\frac{2 c_0(r_1, r_2)}{1+C_T+\\sqrt{C_T^2+4}},\n\\end{equation}\nwhere the domain $\\omega$ and the constant $c_0(r_1, r_2)$ are defined in lemma \\ref{equiv}.\n\\end{theorem}\\begin{proof} From inequality \\eqref{energy_equiv} we get the following estimate:\n$$\n{\\mathcal A}_{rs}^{-1}\\leqslant c^{-1}_0(r_1, r_2){\\mathcal A}_{00}^{-1}.\n$$\nThis estimate and \\eqref{spectr-equiv} yield\n$$\nB{\\mathcal A}_{rs}^{-1}B^T\\leqslant c^{-1}_0(r_1, r_2) B{\\mathcal A}_{00}^{-1}B^T \\leqslant c^{-1}_0(r_1, r_2)(1+C_T+\\sqrt{C_T^2+4}) D.\n$$\nThus, assumption \\eqref{AB} is satisfied if the iterative parameter $\\rho$ satisfies the inequality  $\\displaystyle c^{-1}_0(r_1, r_2)(1+C_T+\\sqrt{C_T^2+4}<\\frac{2}{\\rho},$ which is just \\eqref{iter-step}.\n\\end{proof}{\\bf Implementation}. On every step of method  \\eqref{iter}, \\eqref{iter1} we have to solve three inclusions  \\eqref{iter} with diagonal matrices and diagonal operators. Solving  the inclusions reduces to pointwise projections (for all coordinates of nodal vectors on every time level) on the corresponding sets of the constraints.\n\nSolving a system of linear equations with the matrix  $LM^{-1}L^T$ consists of sequential solution of the systems with the matrices $L$ and $L^T$. In the particular case of the explicit finite difference approximation of state equation  ($\\sigma=0$) these matrices are triangle ones and the solutions can be found  by explicit calculations.\n\n"
        ]
    },
    "errors": [
        "email",
        "shorttit"
    ]
}